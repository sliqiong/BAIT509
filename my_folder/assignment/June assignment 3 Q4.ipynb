{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAIT 509 Assignment 3 \n",
    "\n",
    "__Name__: Liqiong Sun\n",
    "\n",
    "__Student_number__: 75956961"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4 (30%): Fitting SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, you're expected to use the auto_data.csv dataset, not the mtcars data set. The name and mpg columns should not be used as predictors. Your task is to use SVM to predict whether a car has high or low mileage (column mileage) using two methods:\n",
    "\n",
    "1. An SVM with a linear kernel (so, a basic support vector classifier)\n",
    "2. An SVM with a radial basis kernel\n",
    "\n",
    "Answer the following questions:\n",
    "\n",
    "1. Split the data into random training and validation sets. Set aside 40% of the data for the validation set.\n",
    "2. Fit the two models over a grid of hyperparameters, and report the validation error in all cases. You can report them in a table, or a plot. To make things easy, you don't have to choose a fine grid, as long as the optimal hyperparameters are located somewhere in the range of the grid.\n",
    "3. For both methods, what hyperparameter(s) on your grid has the best validation error? Of these two models, which one is better, the linear or radial?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer to 3__ : For linear model, when c = 10, it has lowest validation error of 0.102. For radial basis model, when gamma=1e-05 and c =100, it has lowest validation error of 0.096. In conclusion, linear model is better as it is more stable than radial basis model and it have overall smaller validation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
      "0    18.0          8         307.0         130  3504.0          12.0    70   \n",
      "1    15.0          8         350.0         165  3693.0          11.5    70   \n",
      "2    18.0          8         318.0         150  3436.0          11.0    70   \n",
      "3    16.0          8         304.0         150  3433.0          12.0    70   \n",
      "4    17.0          8         302.0         140  3449.0          10.5    70   \n",
      "5    15.0          8         429.0         198  4341.0          10.0    70   \n",
      "6    14.0          8         454.0         220  4354.0           9.0    70   \n",
      "7    14.0          8         440.0         215  4312.0           8.5    70   \n",
      "8    14.0          8         455.0         225  4425.0          10.0    70   \n",
      "9    15.0          8         390.0         190  3850.0           8.5    70   \n",
      "10   15.0          8         383.0         170  3563.0          10.0    70   \n",
      "11   14.0          8         340.0         160  3609.0           8.0    70   \n",
      "12   15.0          8         400.0         150  3761.0           9.5    70   \n",
      "13   14.0          8         455.0         225  3086.0          10.0    70   \n",
      "14   24.0          4         113.0          95  2372.0          15.0    70   \n",
      "15   22.0          6         198.0          95  2833.0          15.5    70   \n",
      "16   18.0          6         199.0          97  2774.0          15.5    70   \n",
      "17   21.0          6         200.0          85  2587.0          16.0    70   \n",
      "18   27.0          4          97.0          88  2130.0          14.5    70   \n",
      "19   26.0          4          97.0          46  1835.0          20.5    70   \n",
      "20   25.0          4         110.0          87  2672.0          17.5    70   \n",
      "21   24.0          4         107.0          90  2430.0          14.5    70   \n",
      "22   25.0          4         104.0          95  2375.0          17.5    70   \n",
      "23   26.0          4         121.0         113  2234.0          12.5    70   \n",
      "24   21.0          6         199.0          90  2648.0          15.0    70   \n",
      "25   10.0          8         360.0         215  4615.0          14.0    70   \n",
      "26   10.0          8         307.0         200  4376.0          15.0    70   \n",
      "27   11.0          8         318.0         210  4382.0          13.5    70   \n",
      "28    9.0          8         304.0         193  4732.0          18.5    70   \n",
      "29   27.0          4          97.0          88  2130.0          14.5    71   \n",
      "..    ...        ...           ...         ...     ...           ...   ...   \n",
      "362  28.0          4         112.0          88  2605.0          19.6    82   \n",
      "363  27.0          4         112.0          88  2640.0          18.6    82   \n",
      "364  34.0          4         112.0          88  2395.0          18.0    82   \n",
      "365  31.0          4         112.0          85  2575.0          16.2    82   \n",
      "366  29.0          4         135.0          84  2525.0          16.0    82   \n",
      "367  27.0          4         151.0          90  2735.0          18.0    82   \n",
      "368  24.0          4         140.0          92  2865.0          16.4    82   \n",
      "369  36.0          4         105.0          74  1980.0          15.3    82   \n",
      "370  37.0          4          91.0          68  2025.0          18.2    82   \n",
      "371  31.0          4          91.0          68  1970.0          17.6    82   \n",
      "372  38.0          4         105.0          63  2125.0          14.7    82   \n",
      "373  36.0          4          98.0          70  2125.0          17.3    82   \n",
      "374  36.0          4         120.0          88  2160.0          14.5    82   \n",
      "375  36.0          4         107.0          75  2205.0          14.5    82   \n",
      "376  34.0          4         108.0          70  2245.0          16.9    82   \n",
      "377  38.0          4          91.0          67  1965.0          15.0    82   \n",
      "378  32.0          4          91.0          67  1965.0          15.7    82   \n",
      "379  38.0          4          91.0          67  1995.0          16.2    82   \n",
      "380  25.0          6         181.0         110  2945.0          16.4    82   \n",
      "381  38.0          6         262.0          85  3015.0          17.0    82   \n",
      "382  26.0          4         156.0          92  2585.0          14.5    82   \n",
      "383  22.0          6         232.0         112  2835.0          14.7    82   \n",
      "384  32.0          4         144.0          96  2665.0          13.9    82   \n",
      "385  36.0          4         135.0          84  2370.0          13.0    82   \n",
      "386  27.0          4         151.0          90  2950.0          17.3    82   \n",
      "387  27.0          4         140.0          86  2790.0          15.6    82   \n",
      "388  44.0          4          97.0          52  2130.0          24.6    82   \n",
      "389  32.0          4         135.0          84  2295.0          11.6    82   \n",
      "390  28.0          4         120.0          79  2625.0          18.6    82   \n",
      "391  31.0          4         119.0          82  2720.0          19.4    82   \n",
      "\n",
      "     origin                               name  mileage  \n",
      "0         1          chevrolet chevelle malibu        0  \n",
      "1         1                  buick skylark 320        0  \n",
      "2         1                 plymouth satellite        0  \n",
      "3         1                      amc rebel sst        0  \n",
      "4         1                        ford torino        0  \n",
      "5         1                   ford galaxie 500        0  \n",
      "6         1                   chevrolet impala        0  \n",
      "7         1                  plymouth fury iii        0  \n",
      "8         1                   pontiac catalina        0  \n",
      "9         1                 amc ambassador dpl        0  \n",
      "10        1                dodge challenger se        0  \n",
      "11        1                 plymouth 'cuda 340        0  \n",
      "12        1              chevrolet monte carlo        0  \n",
      "13        1            buick estate wagon (sw)        0  \n",
      "14        3              toyota corona mark ii        1  \n",
      "15        1                    plymouth duster        0  \n",
      "16        1                         amc hornet        0  \n",
      "17        1                      ford maverick        0  \n",
      "18        3                       datsun pl510        1  \n",
      "19        2       volkswagen 1131 deluxe sedan        1  \n",
      "20        2                        peugeot 504        1  \n",
      "21        2                        audi 100 ls        1  \n",
      "22        2                           saab 99e        1  \n",
      "23        2                           bmw 2002        1  \n",
      "24        1                        amc gremlin        0  \n",
      "25        1                          ford f250        0  \n",
      "26        1                          chevy c20        0  \n",
      "27        1                         dodge d200        0  \n",
      "28        1                           hi 1200d        0  \n",
      "29        3                       datsun pl510        1  \n",
      "..      ...                                ...      ...  \n",
      "362       1                 chevrolet cavalier        1  \n",
      "363       1           chevrolet cavalier wagon        1  \n",
      "364       1          chevrolet cavalier 2-door        1  \n",
      "365       1         pontiac j2000 se hatchback        1  \n",
      "366       1                     dodge aries se        1  \n",
      "367       1                    pontiac phoenix        1  \n",
      "368       1               ford fairmont futura        1  \n",
      "369       2                volkswagen rabbit l        1  \n",
      "370       3                 mazda glc custom l        1  \n",
      "371       3                   mazda glc custom        1  \n",
      "372       1             plymouth horizon miser        1  \n",
      "373       1                     mercury lynx l        1  \n",
      "374       3                   nissan stanza xe        1  \n",
      "375       3                       honda accord        1  \n",
      "376       3                     toyota corolla        1  \n",
      "377       3                        honda civic        1  \n",
      "378       3                 honda civic (auto)        1  \n",
      "379       3                      datsun 310 gx        1  \n",
      "380       1              buick century limited        1  \n",
      "381       1  oldsmobile cutlass ciera (diesel)        1  \n",
      "382       1         chrysler lebaron medallion        1  \n",
      "383       1                     ford granada l        0  \n",
      "384       3                   toyota celica gt        1  \n",
      "385       1                  dodge charger 2.2        1  \n",
      "386       1                   chevrolet camaro        1  \n",
      "387       1                    ford mustang gl        1  \n",
      "388       2                          vw pickup        1  \n",
      "389       1                      dodge rampage        1  \n",
      "390       1                        ford ranger        1  \n",
      "391       1                         chevy s-10        1  \n",
      "\n",
      "[392 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "df1 = pd.read_csv('./auto_data.csv')\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df1.drop([\"mileage\",\"mpg\",\"name\"], axis=1)\n",
    "Y = df1[\"mileage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_scaled = scale(X)\n",
    "training_X, testing_X, training_Y, testing_Y = train_test_split(X_scaled, Y, test_size=0.4, random_state=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters = {'kernel': ['rbf', 'linear'], 'gamma': [1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8],\n",
    "                     'C': [1, 10, 100, 1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.102 for {kernel: rbf, C: 1, gamma: 0.001}\n",
      "0.732 for {kernel: rbf, C: 1, gamma: 0.0001}\n",
      "0.732 for {kernel: rbf, C: 1, gamma: 1e-05}\n",
      "0.732 for {kernel: rbf, C: 1, gamma: 1e-06}\n",
      "0.732 for {kernel: rbf, C: 1, gamma: 1e-07}\n",
      "0.732 for {kernel: rbf, C: 1, gamma: 1e-08}\n",
      "0.115 for {kernel: rbf, C: 10, gamma: 0.001}\n",
      "0.102 for {kernel: rbf, C: 10, gamma: 0.0001}\n",
      "0.732 for {kernel: rbf, C: 10, gamma: 1e-05}\n",
      "0.732 for {kernel: rbf, C: 10, gamma: 1e-06}\n",
      "0.732 for {kernel: rbf, C: 10, gamma: 1e-07}\n",
      "0.732 for {kernel: rbf, C: 10, gamma: 1e-08}\n",
      "0.115 for {kernel: rbf, C: 100, gamma: 0.001}\n",
      "0.115 for {kernel: rbf, C: 100, gamma: 0.0001}\n",
      "0.096 for {kernel: rbf, C: 100, gamma: 1e-05}\n",
      "0.732 for {kernel: rbf, C: 100, gamma: 1e-06}\n",
      "0.732 for {kernel: rbf, C: 100, gamma: 1e-07}\n",
      "0.732 for {kernel: rbf, C: 100, gamma: 1e-08}\n",
      "0.115 for {kernel: rbf, C: 1000, gamma: 0.001}\n",
      "0.115 for {kernel: rbf, C: 1000, gamma: 0.0001}\n",
      "0.115 for {kernel: rbf, C: 1000, gamma: 1e-05}\n",
      "0.096 for {kernel: rbf, C: 1000, gamma: 1e-06}\n",
      "0.732 for {kernel: rbf, C: 1000, gamma: 1e-07}\n",
      "0.732 for {kernel: rbf, C: 1000, gamma: 1e-08}\n",
      "0.108 for {kernel: linear, C: 1}\n",
      "0.102 for {kernel: linear, C: 10}\n",
      "0.108 for {kernel: linear, C: 100}\n",
      "0.108 for {kernel: linear, C: 1000}\n"
     ]
    }
   ],
   "source": [
    "res = {}\n",
    "for k in tuned_parameters['kernel']:\n",
    "    res[k] = {}\n",
    "    for c in tuned_parameters['C']:\n",
    "        if k == 'linear':\n",
    "            # gamma is not for linear kernel\n",
    "            clf = svm.SVC(kernel=k, C=c)\n",
    "            clf.fit(training_X, training_Y)\n",
    "            test_error = clf.score(testing_X, testing_Y)\n",
    "#             pred = clf.predict(testing_X)\n",
    "            #test_error = np.sum(np.abs(pred-testing_Y)) / len(testing_Y)\n",
    "            res[k][c] = 1-test_error\n",
    "            print('{:.3f} for {{kernel: {}, C: {}}}'.format(res[k][c], k, c))\n",
    "            continue\n",
    "        res[k][c] = {}\n",
    "        for g in tuned_parameters['gamma']:\n",
    "            clf = svm.SVC(kernel=k, C=c, gamma=g)\n",
    "            clf.fit(training_X, training_Y)\n",
    "            test_error = clf.score(testing_X, testing_Y)\n",
    "#             pred = clf.predict(testing_X)\n",
    "#             test_error = np.sum(np.abs(pred-testing_Y)) / len(testing_Y)\n",
    "            res[k][c][g] = 1-test_error\n",
    "            print('{:.3f} for {{kernel: {}, C: {}, gamma: {}}}'.format(res[k][c][g], k, c, g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________\n",
      "| linear |       |\n",
      "==================\n",
      "| C=1    | 0.108 |\n",
      "| C=10   | 0.102 |\n",
      "| C=100  | 0.108 |\n",
      "| C=1000 | 0.108 |\n",
      "____________________________________________________________________________________________________\n",
      "| rbf    | gamma=0.001  | gamma=0.0001 | gamma=1e-05  | gamma=1e-06  | gamma=1e-07  | gamma=1e-08  |\n",
      "====================================================================================================\n",
      "| C=1    | 0.102        | 0.732        | 0.732        | 0.732        | 0.732        | 0.732        |\n",
      "| C=10   | 0.115        | 0.102        | 0.732        | 0.732        | 0.732        | 0.732        |\n",
      "| C=100  | 0.115        | 0.115        | 0.096        | 0.732        | 0.732        | 0.732        |\n",
      "| C=1000 | 0.115        | 0.115        | 0.115        | 0.096        | 0.732        | 0.732        |\n"
     ]
    }
   ],
   "source": [
    "# formating validation error for linear kernel\n",
    "print('{:_<18}'.format(''))\n",
    "print('| {:<4} | {:<5} |'.format('linear', ''))\n",
    "print('{:=<18}'.format(''))\n",
    "for c in res['linear']:\n",
    "    print('| C={:<4} | {:.3f} |'.format(c, res['linear'][c]))\n",
    "\n",
    "print('{:_<100}'.format(''))\n",
    "print('| {:<6} |'.format('rbf'), end='')\n",
    "for g in tuned_parameters['gamma']:\n",
    "    print(' gamma={:<6} |'.format(g), end='')\n",
    "print()\n",
    "print('{:=<100}'.format(''))\n",
    "for c in res['rbf']:\n",
    "    print('| C={:<4} |'.format(c), end='')\n",
    "    for g in res['rbf'][c]:\n",
    "         print(' {:<12.3f} |'.format(res['rbf'][c][g]), end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on validation set:\n",
      "\n",
      "{'C': 1, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on validation set:\n",
      "\n",
      "0.764 (+/-0.000) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.847 (+/-0.000) for {'C': 1, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "0.779 (+/-0.000) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.847 (+/-0.000) for {'C': 1, 'gamma': 0.0001, 'kernel': 'linear'}\n",
      "0.807 (+/-0.000) for {'C': 1, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.847 (+/-0.000) for {'C': 1, 'gamma': 1e-05, 'kernel': 'linear'}\n",
      "0.774 (+/-0.000) for {'C': 1, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.847 (+/-0.000) for {'C': 1, 'gamma': 1e-06, 'kernel': 'linear'}\n",
      "0.783 (+/-0.000) for {'C': 1, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "0.847 (+/-0.000) for {'C': 1, 'gamma': 1e-07, 'kernel': 'linear'}\n",
      "0.804 (+/-0.000) for {'C': 1, 'gamma': 1e-08, 'kernel': 'rbf'}\n",
      "0.847 (+/-0.000) for {'C': 1, 'gamma': 1e-08, 'kernel': 'linear'}\n",
      "0.766 (+/-0.000) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.831 (+/-0.000) for {'C': 10, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "0.799 (+/-0.000) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.831 (+/-0.000) for {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'}\n",
      "0.791 (+/-0.000) for {'C': 10, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.831 (+/-0.000) for {'C': 10, 'gamma': 1e-05, 'kernel': 'linear'}\n",
      "0.794 (+/-0.000) for {'C': 10, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.831 (+/-0.000) for {'C': 10, 'gamma': 1e-06, 'kernel': 'linear'}\n",
      "0.762 (+/-0.000) for {'C': 10, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "0.831 (+/-0.000) for {'C': 10, 'gamma': 1e-07, 'kernel': 'linear'}\n",
      "0.783 (+/-0.000) for {'C': 10, 'gamma': 1e-08, 'kernel': 'rbf'}\n",
      "0.831 (+/-0.000) for {'C': 10, 'gamma': 1e-08, 'kernel': 'linear'}\n",
      "0.754 (+/-0.000) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.831 (+/-0.000) for {'C': 100, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "0.744 (+/-0.000) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.831 (+/-0.000) for {'C': 100, 'gamma': 0.0001, 'kernel': 'linear'}\n",
      "0.788 (+/-0.000) for {'C': 100, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.831 (+/-0.000) for {'C': 100, 'gamma': 1e-05, 'kernel': 'linear'}\n",
      "0.788 (+/-0.000) for {'C': 100, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.831 (+/-0.000) for {'C': 100, 'gamma': 1e-06, 'kernel': 'linear'}\n",
      "0.789 (+/-0.000) for {'C': 100, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "0.831 (+/-0.000) for {'C': 100, 'gamma': 1e-07, 'kernel': 'linear'}\n",
      "0.762 (+/-0.000) for {'C': 100, 'gamma': 1e-08, 'kernel': 'rbf'}\n",
      "0.831 (+/-0.000) for {'C': 100, 'gamma': 1e-08, 'kernel': 'linear'}\n",
      "0.754 (+/-0.000) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.831 (+/-0.000) for {'C': 1000, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "0.731 (+/-0.000) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.831 (+/-0.000) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'linear'}\n",
      "0.803 (+/-0.000) for {'C': 1000, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.831 (+/-0.000) for {'C': 1000, 'gamma': 1e-05, 'kernel': 'linear'}\n",
      "0.797 (+/-0.000) for {'C': 1000, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.831 (+/-0.000) for {'C': 1000, 'gamma': 1e-06, 'kernel': 'linear'}\n",
      "0.783 (+/-0.000) for {'C': 1000, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "0.831 (+/-0.000) for {'C': 1000, 'gamma': 1e-07, 'kernel': 'linear'}\n",
      "0.761 (+/-0.000) for {'C': 1000, 'gamma': 1e-08, 'kernel': 'rbf'}\n",
      "0.831 (+/-0.000) for {'C': 1000, 'gamma': 1e-08, 'kernel': 'linear'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import PredefinedSplit\n",
    "# test_fold_idx = np.zeros(len(X))\n",
    "# for i in range(int(len(X) * 0.6)):\n",
    "#     test_fold_idx[i] = -1\n",
    "\n",
    "# cv = PredefinedSplit(test_fold_idx)\n",
    "# scores = ['precision']\n",
    "\n",
    "# for score in scores:\n",
    "#     print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "#     print()\n",
    "\n",
    "#     clf = GridSearchCV(svm.SVC(), tuned_parameters, cv=cv,\n",
    "#                        scoring='%s_macro' % score)\n",
    "#     clf.fit(X, Y)\n",
    "  \n",
    "#     print(\"Best parameters set found on validation set:\")\n",
    "#     print()\n",
    "#     print(clf.best_params_)\n",
    "#     print()\n",
    "#     print(\"Grid scores on validation set:\")\n",
    "#     print()\n",
    "#     means = clf.cv_results_['mean_test_score']\n",
    "#     stds = clf.cv_results_['std_test_score']\n",
    "#     for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "#         print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "#               % (mean, std * 2, params))\n",
    "#     print()\n",
    "\n",
    "#     print(\"Detailed classification report:\")\n",
    "#     print()\n",
    "#     print(\"The model is trained on the full development set.\")\n",
    "#     print(\"The scores are computed on the full evaluation set.\")\n",
    "#     print()\n",
    "#     testing_Y, predicting_Y = testing_Y, clf.predict(testing_X)\n",
    "#     print(classification_report(testing_Y, predicting_Y))\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kernels = ['rbf', 'linear']\n",
    "# validation_error_kernel = {'rbf': [], 'linear': []}\n",
    "# means = clf.cv_results_['mean_test_score']\n",
    "# for mean, params in zip(means, clf.cv_results_['params']):\n",
    "#     validation_error_kernel[params['kernel']].append((1-mean, params['C'], params['gamma']))\n",
    "#     #print(\"%0.3f for %r\" % (1-mean, params))\n",
    "# #print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
